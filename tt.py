import os
import time
import base64
import streamlit as st
import sounddevice as sd
import numpy as np
import scipy.io.wavfile as wav
from gtts import gTTS
import google.generativeai as genai
import re
import tempfile # Added for temporary file handling

# ==== Configuration ====
st.set_page_config(page_title="ğŸ—£ à®¤à®®à®¿à®´à¯ à®‰à®¤à®µà®¿à®¯à®¾à®³à®°à¯", layout="wide")

# ==== Gemini Setup ====
# Replace with your actual API key
# SECURITY WARNING: Hardcoding API keys directly in source code is NOT recommended for production applications.
# Consider using environment variables or Streamlit Secrets for better security.
API_KEY = "AIzaSyC9mr7-JTjX6ZlHVfGzxRZ1StM2QCBIKCg" # Replace with your actual API key
genai.configure(api_key=API_KEY)

try:
    model = genai.GenerativeModel("models/gemini-1.5-flash")
except Exception as e:
    st.error(f"âŒ Gemini Model Initialization Error: {e}")
    st.stop() # Stop execution if model fails to load

# ==== Chat Bubble Style ====
st.markdown("""
    <style>
    .chat-container {
        display: flex;
        flex-direction: column;
        gap: 10px;
        width: 100%;
        max-width: 90%; /* Increased max-width */
        margin: 20px auto; /* Added margin for better spacing */
        padding-bottom: 150px; /* Add padding to make space for input area */
    }
    .chat-bubble {
        max-width: 75%;
        padding: 10px 15px;
        margin: 5px 0; /* Reduced margin */
        border-radius: 15px;
        line-height: 1.6;
        font-size: 16px;
        clear: both; /* Ensure proper floating */
        word-wrap: break-word; /* Ensure long words break */
    }
    .user-bubble {
        background-color: #38bdf8;
        color: black;
        float: right;
        text-align: right;
        margin-left: 25%; /* Auto margin pushes it right */
    }
    .bot-bubble {
        background-color: #14532d; /* Dark green */
        color: white;
        float: left;
        text-align: left;
        margin-right: 25%; /* Auto margin pushes it left */
    }
    .input-area-container {
        position: fixed; /* Fixed position */
        bottom: 0; /* At the bottom */
        left: 0; /* Spans full width */
        width: 100%;
        background-color: #1e1e1e; /* Dark background for input area */
        padding: 10px 0;
        box-shadow: 0 -2px 10px rgba(0,0,0,0.1); /* Shadow at the top */
        z-index: 1000; /* Ensure it's on top */
    }
    .input-area {
        display: flex;
        justify-content: center; /* Center the button */
        width: 100%;
        max-width: 90%;
        margin: 0 auto;
    }
    .audio-button {
        padding: 12px 20px;
        border-radius: 25px;
        background-color: #38bdf8;
        color: white;
        font-size: 18px;
        cursor: pointer;
        border: none;
        display: inline-block; /* Ensure button properties */
    }
    .audio-button:hover {
        background-color: #0ea5e9;
    }
     .refresh-button {
        position: fixed;
        top: 10px;
        right: 10px;
        padding: 10px 15px;
        border-radius: 5px;
        background-color: #f97316;
        color: white;
        font-size: 14px;
        cursor: pointer;
        border: none;
        z-index: 1000; /* Ensure it's on top */
    }
    .refresh-button:hover {
        background-color: #fb923c;
    }
    .audio-player-container {
        margin-top: 10px;
        text-align: left; /* Align audio player to the left */
    }
    </style>
""", unsafe_allow_html=True)

# ==== Helper: Record Audio ====
def record_audio(duration=8, samplerate=16000):
    """Records audio for a given duration and returns the audio data."""
    st.info("ğŸ¤ à®¤à¯†à®³à®¿à®µà®¾à®•à®µà¯à®®à¯, à®…à®®à¯ˆà®¤à®¿à®¯à®¾à®© à®šà¯‚à®´à®²à®¿à®²à¯à®®à¯ à®ªà¯‡à®šà¯à®™à¯à®•à®³à¯... à®ªà®¤à®¿à®µà¯ à®¤à¯Šà®Ÿà®™à¯à®•à¯à®•à®¿à®±à®¤à¯...")
    time.sleep(0.5)
    try:
        # Check available devices
        devices = sd.query_devices()
        # print("Available audio devices:")
        # for i, device in enumerate(devices):
        #     print(f"{i}: {device['name']}")

        # You might need to select a specific device index if default doesn't work
        # sd.default.device = YOUR_DEVICE_INDEX # Uncomment and set your device index if needed

        recording = sd.rec(int(samplerate * duration), samplerate=samplerate, channels=1, dtype=np.int16)
        sd.wait()  # Wait until recording is finished
        st.info("ğŸ¤ à®ªà®¤à®¿à®µà¯ à®®à¯à®Ÿà®¿à®¨à¯à®¤à®¤à¯!")
        time.sleep(0.2)
        return recording, samplerate
    except Exception as e:
        st.error(f"âŒ Audio Recording Error: {e}")
        st.warning("à®‰à®™à¯à®•à®³à¯ à®®à¯ˆà®•à¯à®°à¯‹à®ƒà®ªà¯‹à®©à¯ à®šà®°à®¿à®¯à®¾à®• à®‡à®£à¯ˆà®•à¯à®•à®ªà¯à®ªà®Ÿà¯à®Ÿà¯à®³à¯à®³à®¤à®¾ à®®à®±à¯à®±à¯à®®à¯ à®…à®©à¯à®®à®¤à®¿ à®µà®´à®™à¯à®•à®ªà¯à®ªà®Ÿà¯à®Ÿà¯à®³à¯à®³à®¤à®¾ à®à®©à¯à®ªà®¤à¯ˆà®šà¯ à®šà®°à®¿à®ªà®¾à®°à¯à®•à¯à®•à®µà¯à®®à¯.") # Check if mic is connected and permissions granted
        return None, None


# ==== Helper: Save Audio to WAV ====
def save_audio_to_wav(audio_data, samplerate):
    """Saves numpy audio data to a temporary WAV file."""
    if audio_data is None or samplerate is None:
        return None
    try:
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
            filepath = tmp_file.name
            wav.write(filepath, samplerate, audio_data)
            return filepath
    except Exception as e:
        st.error(f"âŒ Error saving WAV file: {e}")
        return None

# ==== Helper: Audio to Base64 ====
def audio_to_base64(filepath):
    """Converts an audio file to a Base64 string."""
    if not os.path.exists(filepath):
        return None
    try:
        with open(filepath, "rb") as f:
            return base64.b64encode(f.read()).decode()
    except Exception as e:
        st.error(f"âŒ Error encoding audio to Base64: {e}")
        return None

# ==== Gemini Transcription ====
def transcribe_with_gemini(audio_path):
    """Transcribes audio using the Gemini model."""
    if audio_path is None or not os.path.exists(audio_path):
        return "âš  à®†à®Ÿà®¿à®¯à¯‹ à®•à¯‹à®ªà¯à®ªà¯ à®•à®¿à®Ÿà¯ˆà®•à¯à®•à®µà®¿à®²à¯à®²à¯ˆ." # Audio file not available

    audio_base64 = audio_to_base64(audio_path)
    if audio_base64 is None:
        return "âš  à®†à®Ÿà®¿à®¯à¯‹à®µà¯ˆ à®šà¯†à®¯à®²à®¾à®•à¯à®• à®®à¯à®Ÿà®¿à®¯à®µà®¿à®²à¯à®²à¯ˆ." # Could not process audio

    prompt = (
        "à®‡à®¨à¯à®¤ à®†à®Ÿà®¿à®¯à¯‹à®µà®¿à®²à¯ à®ªà¯‡à®šà®ªà¯à®ªà®Ÿà¯à®µà®¤à¯ˆà®•à¯ à®•à®µà®©à®®à®¾à®•à®•à¯ à®•à¯‡à®Ÿà¯à®Ÿà¯, "
        "à®…à®¤à¯ˆ à®¤à®®à®¿à®´à¯ à®à®´à¯à®¤à¯à®¤à®¾à®• à®®à®¾à®±à¯à®±à®µà¯à®®à¯. à®µà¯‡à®±à¯ à®à®¨à¯à®¤ à®µà®¿à®³à®•à¯à®•à®®à¯à®®à¯ à®šà¯‡à®°à¯à®•à¯à®• à®µà¯‡à®£à¯à®Ÿà®¾à®®à¯." # Added instruction to not add other explanations
    )
    try:
        response = model.generate_content(
            [prompt, {"mime_type": "audio/wav", "data": audio_base64}]
        )
        # Clean up potential markdown artifacts from the response
        text = response.text.strip()
        text = text.replace("json", "").replace("", "").strip() # Remove potential markdown
        text = re.sub(r"^\s*Transcription:\s*", "", text, flags=re.IGNORECASE) # Remove potential "Transcription:" prefix
        return text if text else "âš  à®Ÿà®¿à®°à®¾à®©à¯à®¸à¯à®•à®¿à®°à®¿à®ªà¯à®·à®©à¯ à®à®¤à¯à®µà¯à®®à¯ à®•à®¿à®Ÿà¯ˆà®•à¯à®•à®µà®¿à®²à¯à®²à¯ˆ." # No transcription available

    except Exception as e:
        st.error(f"âŒ Gemini Speech Error: {e}")
        return f"âš  à®Ÿà®¿à®°à®¾à®©à¯à®¸à¯à®•à®¿à®°à®¿à®ªà¯à®·à®©à¯ à®ªà®¿à®´à¯ˆ: {e}" # Transcription error

# ==== Gemini Chat ====
def query_gemini_tamil(prompt_text):
    """Queries the Gemini model with chat history context."""
    if not prompt_text:
        return "à®¨à¯€à®™à¯à®•à®³à¯ à®à®©à¯à®© à®ªà¯‡à®šà®¿à®©à¯€à®°à¯à®•à®³à¯ à®à®©à¯à®±à¯ à®à®©à®•à¯à®•à¯à®ªà¯ à®ªà¯à®°à®¿à®¯à®µà®¿à®²à¯à®²à¯ˆ. à®¤à®¯à®µà¯à®šà¯†à®¯à¯à®¤à¯ à®®à¯€à®£à¯à®Ÿà¯à®®à¯ à®®à¯à®¯à®±à¯à®šà®¿à®•à¯à®•à®µà¯à®®à¯." # I didn't understand what you said. Please try again.

    context = ""
    # Include the last 6 turns of the conversation in the prompt
    if st.session_state.chat_history:
        context += "à®®à¯à®¨à¯à®¤à¯ˆà®¯ à®‰à®°à¯ˆà®¯à®¾à®Ÿà®²à¯:\n"
        # Iterate through tuples (role, text)
        for i, (role, text) in enumerate(st.session_state.chat_history[-12:]): # Last 12 entries for 6 turns
            if role == "user":
                context += f"à®ªà®¯à®©à®°à¯: {text}\n"
            else:
                context += f"à®‰à®¤à®µà®¿à®¯à®¾à®³à®°à¯: {text}\n"
        context += "\n"

    full_prompt = (
        f"{context}à®‡à®ªà¯à®ªà¯‹à®¤à¯ à®ªà®¯à®©à®°à¯ à®•à¯‡à®Ÿà¯à®•à¯à®®à¯ à®•à¯‡à®³à¯à®µà®¿: {prompt_text}\n\n"
        "à®‡à®¨à¯à®¤à®•à¯ à®•à¯‡à®³à¯à®µà®¿à®•à¯à®•à¯ à®‡à®¯à®±à¯à®•à¯ˆà®¯à®¾à®© à®®à¯à®±à¯ˆà®¯à®¿à®²à¯ à®¤à®®à®¿à®´à®¿à®²à¯ à®ªà®¤à®¿à®²à®³à®¿à®•à¯à®•à®µà¯à®®à¯. à®µà¯‡à®±à¯ à®à®¨à¯à®¤ à®®à¯Šà®´à®¿à®¯à®¿à®²à¯à®®à¯ à®ªà®¤à®¿à®²à®³à®¿à®•à¯à®• à®µà¯‡à®£à¯à®Ÿà®¾à®®à¯. à®ªà®¤à®¿à®²à®¿à®²à¯ à®®à®¾à®°à¯à®•à¯ à®Ÿà®µà¯à®©à¯ à®•à¯à®±à®¿à®¯à¯€à®Ÿà¯à®•à®³à¯ˆ (Markdown) à®¤à®µà®¿à®°à¯à®•à¯à®•à®µà¯à®®à¯." # Respond naturally in Tamil, avoid other languages and markdown
    )

    try:
        response = model.generate_content(full_prompt)
        # Clean up potential markdown artifacts from the response
        text = response.text.strip()
        text = text.replace("```", "").strip() # Remove potential markdown code blocks
        return text if text else "à®®à®©à¯à®©à®¿à®•à¯à®•à®µà¯à®®à¯, à®à®©à¯à®©à®¾à®²à¯ à®ªà®¤à®¿à®²à®³à®¿à®•à¯à®• à®®à¯à®Ÿà®¿à®¯à®µà®¿à®²à¯à®²à¯ˆ." # Sorry, I could not respond.

    except Exception as e:
        st.error(f"âŒ Gemini Chat Error: {e}")
        return f"âš  à®ªà®¤à®¿à®²à®³à®¿à®ªà¯à®ªà®¤à®¿à®²à¯ à®ªà®¿à®´à¯ˆ: {e}" # Error in responding

# ==== Speak Tamil ====
def speak_tamil(text):
    """Converts text to speech using gTTS and returns the audio file path."""
    if not text or text.startswith("âš "): # Don't try to speak error messages
         return None

    # Clean unwanted characters and punctuation from the response
    # Keep Tamil letters, numbers, basic punctuation, and spaces
    cleaned_text = re.sub(r"[^\w\s.,?!()\u0B80-\u0BFF]", "", text)
    cleaned_text = cleaned_text.replace("-", " to ").replace("â€”", " to ") # Convert ranges to words (with spaces)
    cleaned_text = re.sub(r"(\d+)\s?(\d+)", r"\1 to \2", cleaned_text) # Range like 3 5 -> 3 to 5

    if not cleaned_text.strip():
        return None # Don't generate audio for empty string after cleaning

    try:
        with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as tmp_file:
            filename = tmp_file.name
            tts = gTTS(text=cleaned_text, lang='ta')
            tts.save(filename)
            return filename
    except Exception as e:
        st.error(f"âŒ Text-to-Speech Error: {e}")
        return None

def render_audio_player(filepath):
    """Renders an HTML audio player for a given file."""
    if filepath is None or not os.path.exists(filepath):
        return

    audio_base64 = audio_to_base64(filepath)
    if audio_base64:
        audio_html = f"""
            <div class="audio-player-container">
                <audio autoplay controls>
                    <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
                    Your browser does not support the audio element.
                </audio>
            </div>
        """
        st.markdown(audio_html, unsafe_allow_html=True)
        # Clean up the temporary audio file after rendering
        # Note: This might sometimes delete before playback finishes, depending on browser caching.
        # For robustness in production, proper temp file management or client-side cleanup is better.
        try:
            os.unlink(filepath)
        except OSError as e:
             print(f"Error removing temp audio file {filepath}: {e}")


# ==== Session Memory ====
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Limit to last 6 conversations (12 entries)
if len(st.session_state.chat_history) > 12:
    st.session_state.chat_history = st.session_state.chat_history[-12:]

# ==== Clear chat history on refresh button click ====
if st.button("ğŸ”„ Refresh", key="refresh_button_top", help="Click to refresh the page and start a new conversation."):
     st.session_state.chat_history = []
     st.session_state.last_audio = None # Also clear last audio
     st.rerun() # Rerun to clear the display


# ==== Chat UI ====
st.title("ğŸ—£ à®¤à®®à®¿à®´à¯ à®‰à®¤à®µà®¿à®¯à®¾à®³à®°à¯ (Gemini Flash 1.5)")

# Refresh button (redundant with the one above, keeping one)
# st.markdown('<div class="refresh-button"><button onclick="window.location.reload();">ğŸ”„ Refresh</button></div>', unsafe_allow_html=True)


# Chat container
st.markdown('<div class="chat-container">', unsafe_allow_html=True)
# Display history
for role, text in st.session_state.chat_history:
    if role == "user":
        st.markdown(f'<div class="chat-bubble user-bubble">{text}</div>', unsafe_allow_html=True)
    else:
        st.markdown(f'<div class="chat-bubble bot-bubble">{text}</div>', unsafe_allow_html=True)
st.markdown('</div>', unsafe_allow_html=True)

# Input area (fixed at the bottom)
st.markdown('<div class="input-area-container"><div class="input-area">', unsafe_allow_html=True)
if st.button("ğŸ™ à®ªà®¤à®¿à®µà¯ à®šà¯†à®¯à¯ (8 à®µà®¿à®¨à®¾à®Ÿà®¿à®•à®³à¯)", key="record_button", use_container_width=False):
    audio_data, samplerate = record_audio()
    if audio_data is not None and samplerate is not None:
        # Save to temporary file
        audio_path = save_audio_to_wav(audio_data, samplerate)

        if audio_path:
            st.success("âœ… à®ªà®¤à®¿à®µà¯ à®µà¯†à®±à¯à®±à®¿à®•à®°à®®à®¾à®• à®šà¯‡à®®à®¿à®•à¯à®•à®ªà¯à®ªà®Ÿà¯à®Ÿà®¤à¯. à®šà¯†à®¯à®²à¯à®ªà®Ÿà¯à®¤à¯à®¤à¯à®•à®¿à®±à¯‡à®©à¯...") # Recording successfully saved

            # Transcription
            user_text = transcribe_with_gemini(audio_path)

            # Clean up temporary recording file immediately after transcription attempt
            try:
                os.unlink(audio_path)
            except OSError as e:
                 print(f"Error removing temp recording file {audio_path}: {e}")

            st.session_state.chat_history.append(("user", user_text))

            if not user_text.startswith("âš "): # Only query Gemini if transcription was not an error
                # Gemini Response
                bot_text = query_gemini_tamil(user_text)
                st.session_state.chat_history.append(("bot", bot_text))

                # Speak and store audio
                audio_file = speak_tamil(bot_text)
                st.session_state.last_audio = audio_file # Store path to temporary audio file
            else:
                 # If transcription failed, add a default bot message
                 st.session_state.chat_history.append(("bot", "à®®à®©à¯à®©à®¿à®•à¯à®•à®µà¯à®®à¯, à®‰à®™à¯à®•à®³à¯ à®ªà¯‡à®šà¯à®šà¯ˆà®ªà¯ à®ªà¯à®°à®¿à®¨à¯à®¤à¯à®•à¯Šà®³à¯à®³ à®®à¯à®Ÿà®¿à®¯à®µà®¿à®²à¯à®²à¯ˆ.")) # Sorry, could not understand your speech.
                 st.session_state.last_audio = None # No audio to play


            st.rerun() # Rerun to update the chat history and potentially the audio player
        else:
            st.error("âŒ à®†à®Ÿà®¿à®¯à¯‹ à®•à¯‹à®ªà¯à®ªà¯ˆ à®‰à®°à¯à®µà®¾à®•à¯à®• à®®à¯à®Ÿà®¿à®¯à®µà®¿à®²à¯à®²à¯ˆ.") # Could not create audio file

st.markdown('</div></div>', unsafe_allow_html=True)


# Show last audio output for replay below the chat messages
# This needs to be outside the fixed input area container
if "last_audio" in st.session_state and st.session_state.last_audio:
     # Add a placeholder below the chat container for the audio player
     # Use a unique key or position carefully to avoid disappearing
     st.markdown('<div style="height: 100px;"></div>', unsafe_allow_html=True) # Add some space
     render_audio_player(st.session_state.last_audio)
     # Note: Temporary audio file cleanup is attempted within render_audio_player